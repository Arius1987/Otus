## Третья лабораторная работа.

В ней я изначально хотел собрать что-то похожее на clos: proxmox расставить как спайны, коммутаторы arista - лифами (route reflectors). Но не судьба - ибо underlay наш работает на статических маршрутах. Вся проблематика описана в лабе номер 2.
Но что делать, если какую-то отказоусточивость и балансировку получить все-таки очень хочется, а underlay нам рисует индейские националые избы? Не забудем, что под капотом proxmox крутится всемогущий Linux котрый может решить проблему встронными средствами операционной системы. 

Ко второй лабе в добавим еще 1 роутер. Получим такую схему:

![image](https://github.com/user-attachments/assets/149dd703-79d8-4e63-a9b8-39f8dda3851c)

Настою ip адресацию:

![image](https://github.com/user-attachments/assets/a8e1c51b-70bc-4e2c-9cfe-df47b40c32f1)

Жмем ok, потом apply

Не забудем статические маршруты:

![image](https://github.com/user-attachments/assets/c3f562b1-e74b-49a7-b10c-d5b51cbd2698)


Рестартанем сервис сети:

systemctl restart networking.service


Аналогично на втором проксмоксе, и все мы знаем, как настраивать базовый конфиг на cisco ios (там настроена обычная маршрутизация между 10.3.0.0/24 и 10.2.0.0/24)

Отключим проверку обратных маршрутов в /etc/sysctl.conf, чтоб пакет прилетевший условно на ens4, мог уйти обратно через ens5:


net.ipv4.conf.all.rp_filter = 0

net.ipv4.conf.default.rp_filter = 0


Отвяжем маршрут по умолчанию от моего домашнего роутера


ip route add 192.168.5.0/27 via 192.168.5.1

ip route del default


Применим данные настройки:


sysctl -p


Создадим таблицы маршрутизации


echo 200 r5 >> /etc/iproute2/rt_tables

echo 201 r10 >> /etc/iproute2/rt_tables


Где 200 и 201 - номера таблиц, r5 и r10 - их названия

Создадим скрипт для балансировки нагрузки:

nano /usr/local/bin/tr_balance.sh


#!/bin/bash


\# пакеты с ip.src 10.1.0.1 кладем в таблицу r5, а 10.3.0.1 в r10

ip rule add from 10.1.0.1 table r5

ip rule add from 10.3.0.1 table r10

\# два дефолтных маршрута для пакетов, попадающих под правила таблиц r5 и r10

ip route add default via 10.0.0.2 table r5

ip route add default via 10.2.0.2 table r10

\# к обоим маршрутам вешаем default gateway и одинаковую метрику

ip route add default scope global nexthop via 10.0.0.2 dev ens4 weight 2 nexthop via 10.2.0.2 dev ens5 weight 2



Выходим из тела скрипта и делаем скрипт испольнаемым:

chmod +x tr_balance.sh


Рядом создаем второй скрипт:

nano /usr/local/bin/ch_route.py  - почему на питоне, а не на баше? - По тому, что все, что больше 4ех строк я пишу на питоне:

#!/usr/bin/python3


import subprocess


def pinger(dhost_if):
    unpingable = []
    processes = []
    for dstip, inface in dhost_if.items():
        #p = subprocess.Popen(['ping', '-c', '4', ip],
        p = subprocess.Popen(f'ping -c 5 {dstip} -I {inface} -i 1',
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
        encoding='utf-8',
        shell=True
        )
        processes.append(p)
    for dstip, process in zip(dhost_if.keys(), processes):
        returncode = process.wait()
        if not returncode == 0:
            unpingable.append(dstip)
    return unpingable




dhost_gw = {'10.1.0.1': '10.0.0.2',
            '10.3.0.1': '10.2.0.2'}
dhost_if = {'10.1.0.1': 'ens4',
            '10.3.0.1': 'ens5'}


subprocess.run('ip route add 10.1.0.1 via 10.0.0.2', shell=True)
subprocess.run('ip route add 10.3.0.1 via 10.2.0.2', shell=True)

ips = pinger(dhost_if)
if len(ips) > 0:
    for dst_host in ips:
        subprocess.run(f'ip route delete {dst_host} via {dhost_gw[dst_host]}', shell=True)


Выходим, делаем файл исполняемым:

chmod +x ch_route.py

Сам код объяснять не буду на опишу его логику:
1. Прописываем оба статических маршрута к удаленному проксмоксу
2. Пропинговываем удаленный проксмокс из под обоих интерфейсов сморящих на него.
   если пинги идут - закрываем скрипт
   если пинг пропал - удаляем соотв.маршрут, после трафик начинает ходить по осташемуся маршруту
3. Через 20 секунд снова стартуает и начнет выполнять операции с пункта 1, по пунт 2 (вдруг за это время линк восстановился?)

Теперь нужно сделать, чтоб скрипт по балансировке запускался при старте гипервизора, а скрипт пингуюший удалнный хост запускался через каждые 20 секунд. С древних времен для этого существует crontab.
Вводим crontab -e и добаляем строки:

![image](https://github.com/user-attachments/assets/4aab0369-dc60-4f3e-8d55-8eea1317209d)

Аналогичный скрипт нужно теперь написать на соседних гипервизорах.

Давайте посмотрим show команды балансировки маршрутов:

![image](https://github.com/user-attachments/assets/29f89854-ffa8-450c-a9dc-c3a962577ab1)

Видим два дефолтных шлюза через разные gw. Метрику почему-то не показывает, хотя она указывалась при создании этих маршрутов

Теперь посмотрим работу скрипта проверяющего состояние каналов связи. Для этого я запущу tcpdump с фильтром по icmp:

![image](https://github.com/user-attachments/assets/5c28394c-c4a0-480f-b205-abf6f18c892d)

Видим его работу с паузой в между пачкой пингов, и маршуты он удаляет и снова создает - работает в общем.

На этом итоговую я закончил























